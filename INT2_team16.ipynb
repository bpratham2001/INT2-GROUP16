{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INT2_team16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYbroXRKiTSU"
      },
      "source": [
        "Hello There\n",
        "\n",
        "**Here are some useful links to get us all up to speed**\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "https://pytorch.org/vision/stable/datasets.html#cifar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBj-lv08gYSE"
      },
      "source": [
        "#Import modules\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn, optim, cuda\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "WFh3DcjSigAk",
        "outputId": "805838ba-3285-4fd0-9b35-69d250b9fdf8"
      },
      "source": [
        "#Load data\n",
        "\n",
        "device = torch.device('cuda')\n",
        "#device = torch.device('cpu')\n",
        "#batch_sz = 128\n",
        "batch_sz = 32\n",
        "#NET, NET2 DATALOADERS\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "training_data = DataLoader(training_data, batch_size=batch_sz, shuffle=True)\n",
        "test_data = DataLoader(test_data, batch_size=batch_sz, shuffle=True)\n",
        "\n",
        "\"\"\"#CNN, CNN2 DATALOADERS\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]))\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.Resize((32,32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]))\n",
        "\n",
        "training_data = DataLoader(dataset=training_data, batch_size=batch_sz, shuffle=True)\n",
        "test_data = DataLoader(dataset=test_data, batch_size=batch_sz, shuffle=False)\n",
        "\"\"\"\n",
        "#New attempted dataloaders\n",
        "\"\"\"\n",
        "training_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomAffine(0,scale=(0.5,1.5)),\n",
        "        transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\n",
        "        transforms.RandomRotation(20),\n",
        "        transforms.RandomVerticalFlip(0.4),\n",
        "        transforms.RandomHorizontalFlip(0.4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "\n",
        "    ])\n",
        ")\n",
        "\n",
        "training_data = DataLoader(training_data, batch_size=batch_sz, shuffle=True,drop_last=True)\n",
        "\n",
        "test_data = datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        ")\n",
        "test_data = DataLoader(test_data, batch_size=batch_sz, shuffle=True)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntraining_data = datasets.CIFAR10(\\n    root=\"data\",\\n    train=True,\\n    download=True,\\n    transform=transforms.Compose([\\n        transforms.RandomAffine(0,scale=(0.5,1.5)),\\n        transforms.ColorJitter(0.25, 0.25, 0.25, 0.25),\\n        transforms.RandomRotation(20),\\n        transforms.RandomVerticalFlip(0.4),\\n        transforms.RandomHorizontalFlip(0.4),\\n        transforms.ToTensor(),\\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\n\\n    ])\\n)\\n\\ntraining_data = DataLoader(training_data, batch_size=batch_sz, shuffle=True,drop_last=True)\\n\\ntest_data = datasets.CIFAR10(\\n    root=\"data\",\\n    train=False,\\n    download=True,\\n    transform=transforms.Compose([\\n        transforms.ToTensor(),\\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\n    ])\\n)\\ntest_data = DataLoader(test_data, batch_size=batch_sz, shuffle=True)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-hv6uBWj568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "2b80d719-bcc8-4a39-ee42-0f3f5c04f664"
      },
      "source": [
        "#Convolutional Neural Networks\n",
        "\n",
        "#V1 code\n",
        "class V1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=0)\n",
        "        self.fc1 = nn.Linear(32 * 5 * 5, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    def forward(self, x):\n",
        "        batchsz = x.size(0)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.avg_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.avg_pool2d(x, kernel_size=2, stride=2, padding=0)\n",
        "        x = x.view(batchsz, -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "#BENCHMARK NETWORK\n",
        "\"\"\"\n",
        "class NET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "        nn.AvgPool2d( kernel_size=2, stride=2, padding=0),\n",
        "        nn.Conv2d(128, 256, kernel_size=3, stride=2, bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(True),\n",
        "        nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        nn.Conv2d(256, 512, kernel_size=3, stride=2, bias=False))\n",
        " \n",
        "    self.res1 = nn.Sequential(\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, 3, 1, 1, bias=False))\n",
        " \n",
        "    self.res2 = nn.Sequential(\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(512, 512, 3, 1, 1, bias=False))\n",
        " \n",
        "    self.net2 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size=3, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
        "        nn.Dropout(0.2))\n",
        " \n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(512, 10),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(0.2))\n",
        " \n",
        " \n",
        "  def forward(self, image):\n",
        "    feature = self.net(image)\n",
        "    feature = feature + self.res1(feature)\n",
        "    feature = feature + self.res2(feature)\n",
        "    feature = self.net2(feature)\n",
        "    feature = feature.view(-1, 512)\n",
        "    return self.fc(feature)\n",
        "\"\"\" \n",
        "#TEST NETWORK\n",
        "class NET2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=2, bias=False))\n",
        "\n",
        "        self.res1 = nn.Sequential(\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1, bias=False))\n",
        "\n",
        "        self.res2 = nn.Sequential(\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
        "            nn.Conv2d(512, 512, 3, 1, 1, bias=False))\n",
        "\n",
        "        self.net2 = nn.Sequential(\n",
        "            nn.Conv2d(512, 256, kernel_size=3, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 10))\n",
        "\n",
        "    def forward(self, image):\n",
        "        feature = self.net(image)\n",
        "        feature = feature + self.res1(feature)\n",
        "        feature = feature + self.res2(feature)\n",
        "        feature = self.net2(feature)\n",
        "        feature = feature.view(-1, 256)\n",
        "        return self.fc(feature)\n",
        "\n",
        "\n",
        "#BASED ON VGG-13 with Batch Normalisation\n",
        "#https://github.com/chengyangfu/pytorch-vgg-cifar10/blob/master/vgg.py , https://www.kaggle.com/vikasbhadoria/cifar10-high-accuracy-model-build-on-pytorch\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "                                 nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "                                 nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "                                 nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "                                 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "                                 nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "                                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                                )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "                                        nn.Dropout(0.2),\n",
        "                                        nn.Linear(512, 512),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Dropout(0.5),\n",
        "                                        nn.Linear(512, 512),\n",
        "                                        nn.ReLU(True),\n",
        "                                        nn.Linear(512, 10),\n",
        "                                       )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\"\n",
        "# https://arxiv.org/pdf/1409.1556.pdf\n",
        "\"\"\"\n",
        "class VGG16(nn.Module):\n",
        "\n",
        "    def __init__(self, layer_sizes, use_softmax=False):\n",
        "        super(VGG, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            )\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "                  nn.Linear(512, 4096),\n",
        "                  nn.ReLU(True),\n",
        "                  nn.Dropout(),\n",
        "                  nn.Linear(4096, 4096),\n",
        "                  nn.ReLU(True),\n",
        "                  nn.Dropout(),\n",
        "                  nn.Linear(4096, 10)\n",
        "                  )\n",
        "        self.use_softmax = use_softmax\n",
        "  \n",
        "    def forward(self, x):\n",
        "        x = self.network(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        if self.use_softmax:\n",
        "            x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclass VGG16(nn.Module):\\n\\n    def __init__(self, layer_sizes, use_softmax=False):\\n        super(VGG, self).__init__()\\n        self.network = nn.Sequential(\\n            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\\n            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\\n            \\n            nn.MaxPool2d(kernel_size=2, stride=2),\\n\\n            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\\n            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\\n            \\n            nn.MaxPool2d(kernel_size=2, stride=2),\\n            \\n            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\\n            \\n            nn.MaxPool2d(kernel_size=2, stride=2),\\n            \\n            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            \\n            nn.MaxPool2d(kernel_size=2, stride=2),\\n            \\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\\n            \\n            nn.MaxPool2d(kernel_size=2, stride=2)\\n            )\\n        \\n        self.classifier = nn.Sequential(\\n                  nn.Linear(512, 4096),\\n                  nn.ReLU(True),\\n                  nn.Dropout(),\\n                  nn.Linear(4096, 4096),\\n                  nn.ReLU(True),\\n                  nn.Dropout(),\\n                  nn.Linear(4096, 10)\\n                  )\\n        self.use_softmax = use_softmax\\n  \\n    def forward(self, x):\\n        x = self.network(x)\\n        x = torch.flatten(x, 1)\\n        x = self.classifier(x)\\n        if self.use_softmax:\\n            x = F.log_softmax(x, dim=1)\\n        return x\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYeJIDIqAj_9"
      },
      "source": [
        "model = V1().to(device)\n",
        "#model = NET().to(device)\n",
        "#77.44% with batch_sz = 32, OptimiserC, epoch = 132 #OUTDATED\n",
        "#% with batch_sz = 32, OptimiserA, epoch = \n",
        "#model = NET2().to(device)\n",
        "#% with batch_sz = 32, OptimiserC, epoch = \n",
        "#% with batch_sz = 32, OptimiserA, epoch = \n",
        "#model = CNN().to(device)\n",
        "#% with batch_sz = , OptimiserE, epoch = \n",
        "#% with batch_sz = , OptimiserC, epoch = \n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "#optimiser = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.002)       #OptimiserA\n",
        "#optimiser = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)              #OptimiserB\n",
        "optimiser = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)               #OptimiserC\n",
        "#optimiser = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.002)      #OptimiserD\n",
        "#optimiser = torch.optim.Adam(model.parameters(), lr=0.001)                     #OptimiserE (used in CNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5BSwiOXT-zQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a1b084-83a4-45ad-8979-2aacb959be32"
      },
      "source": [
        "#OLD TEST\n",
        "acc = []\n",
        "for epoch in range(1000):\n",
        "    running_loss = 0\n",
        "    for batch_index, (pred, target) in enumerate(training_data):\n",
        "        pred, target = pred.to(device), target.to(device)\n",
        "        optimiser.zero_grad()\n",
        "        output = model(pred)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "        '''\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "          print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "          running_loss = 0\n",
        "        '''\n",
        "    #print(epoch, loss.item())\n",
        " \n",
        "    #test\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        total_num = 0\n",
        "        for pred, target in test_data:\n",
        "            pred, target = pred.to(device), target.to(device)\n",
        "            output = model(pred)\n",
        "            pred = output.argmax(dim=1)\n",
        "            total_correct += torch.eq(pred, target).float().sum().item()\n",
        "            total_num += pred.size(0)\n",
        "        \n",
        "        acc.append(total_correct / total_num)\n",
        "        if epoch % 5 == 0:\n",
        "          print(epoch, np.argmax(acc), max(acc))\n",
        "        \n",
        "        #print(epoch, total_correct / total_num)\n",
        " \n",
        "#torch.save(model.state_dict(), \"cifar-net.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 0.3364\n",
            "5 5 0.5226\n",
            "10 10 0.577\n",
            "15 15 0.5883\n",
            "20 20 0.6044\n",
            "25 25 0.6207\n",
            "30 25 0.6207\n",
            "35 35 0.6241\n",
            "40 39 0.6295\n",
            "45 39 0.6295\n",
            "50 49 0.6325\n",
            "55 49 0.6325\n",
            "60 60 0.6374\n",
            "65 63 0.6392\n",
            "70 69 0.6398\n",
            "75 69 0.6398\n",
            "80 69 0.6398\n",
            "85 69 0.6398\n",
            "90 90 0.6446\n",
            "95 90 0.6446\n",
            "100 90 0.6446\n",
            "105 104 0.6462\n",
            "110 104 0.6462\n",
            "115 115 0.6487\n",
            "120 115 0.6487\n",
            "125 115 0.6487\n",
            "130 115 0.6487\n",
            "135 115 0.6487\n",
            "140 115 0.6487\n",
            "145 143 0.6555\n",
            "150 143 0.6555\n",
            "155 143 0.6555\n",
            "160 143 0.6555\n",
            "165 163 0.6579\n",
            "170 163 0.6579\n",
            "175 163 0.6579\n",
            "180 177 0.6627\n",
            "185 177 0.6627\n",
            "190 177 0.6627\n",
            "195 177 0.6627\n",
            "200 177 0.6627\n",
            "205 177 0.6627\n",
            "210 177 0.6627\n",
            "215 177 0.6627\n",
            "220 177 0.6627\n",
            "225 177 0.6627\n",
            "230 177 0.6627\n",
            "235 177 0.6627\n",
            "240 177 0.6627\n",
            "245 177 0.6627\n",
            "250 177 0.6627\n",
            "255 177 0.6627\n",
            "260 177 0.6627\n",
            "265 177 0.6627\n",
            "270 177 0.6627\n",
            "275 273 0.6638\n",
            "280 273 0.6638\n",
            "285 273 0.6638\n",
            "290 273 0.6638\n",
            "295 273 0.6638\n",
            "300 273 0.6638\n",
            "305 303 0.6668\n",
            "310 303 0.6668\n",
            "315 303 0.6668\n",
            "320 303 0.6668\n",
            "325 322 0.6672\n",
            "330 322 0.6672\n",
            "335 322 0.6672\n",
            "340 322 0.6672\n",
            "345 322 0.6672\n",
            "350 322 0.6672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7xKqQjIWyAl"
      },
      "source": [
        "#VERBOSE TEST\n",
        "epochs = 1000\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "test_running_loss_history = []\n",
        "test_running_corrects_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    test_running_loss = 0.0\n",
        "    test_running_corrects = 0.0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(predictions == labels.data)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            for test_inputs, test_labels in test_loader:\n",
        "                test_inputs = test_inputs.to(device)\n",
        "                test_labels = test_labels.to(device)\n",
        "                test_outputs = model(test_inputs)\n",
        "\n",
        "                test_loss = criterion(test_outputs, test_labels)\n",
        "\n",
        "                _, test_predictions = torch.max(test_outputs, 1)\n",
        "                test_running_loss += test_loss.item()\n",
        "                test_running_corrects += torch.sum(test_predictions == test_labels.data)\n",
        "\n",
        "        epoch_loss = running_loss/len(train_loader)\n",
        "        epoch_accuracy = float(running_corrects)/len(train_loader)\n",
        "        running_loss_history.append(epoch_loss)\n",
        "        running_corrects_history.append(epoch_accuracy)\n",
        "\n",
        "        test_epoch_loss = test_running_loss/len(test_loader)\n",
        "        test_epoch_accuracy = float(test_running_corrects)/len(test_loader)\n",
        "        test_running_loss_history.append(test_epoch_loss)\n",
        "        test_running_corrects_history.append(test_epoch_accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}\", \"|\",\n",
        "              f\"Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\", \"|\",\n",
        "              f\"Testing Loss: {test_epoch_loss:.4f}, Accuracy: {test_epoch_accuracy:.4f}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}